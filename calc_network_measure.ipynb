{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrrir0itjh4n++tSKWR3fN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udayameister/Connectome/blob/main/calc_network_measure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sza9fpv0hm_A"
      },
      "outputs": [],
      "source": [
        "\n",
        "### IMPORT PACKAGES\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import igraph as ig\n",
        "from igraph import *\n",
        "from scipy import stats\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "from igraph import Graph\n",
        "from igraph import plot\n",
        "from igraph import GraphBase\n",
        "from igraph.clustering import*\n",
        "from scipy import stats\n",
        "import igraph\n",
        "from igraph import Clustering\n",
        "from igraph import VertexDendrogram\n",
        "from igraph import VertexClustering\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "### FUNCTION DEFINITION\n",
        "def normalize(matrix):\n",
        "    return stats.zscore(matrix)\n",
        "\n",
        "\n",
        "def graph3(x):\n",
        "    test1 = np.array(x)\n",
        "    graphx = Graph.Adjacency(test1.tolist(), mode='UNDIRECTED')\n",
        "    graphx1= GraphBase.simplify(graphx,multiple=True, loops=True, combine_edges=None)\n",
        "    return graphx1\n",
        "\n",
        "\n",
        "def assortativity(x):\n",
        "    coefficient_assortativity=GraphBase.assortativity_degree(x, directed=False)\n",
        "    return coefficient_assortativity\n",
        "\n",
        "def Shannon_entropy(distribution):\n",
        "    entropia=stats.entropy(distribution)\n",
        "    return entropia\n",
        "def average_path_length(x):\n",
        "    apl=GraphBase.average_path_length(x,directed=False, unconn=True)\n",
        "    return apl\n",
        "\n",
        "def betweenness(x):\n",
        "    bc=np.mean(sorted(GraphBase.betweenness(x)))\n",
        "    return bc\n",
        "\n",
        "def closeness(x):\n",
        "    cc=GraphBase.closeness(x)\n",
        "    for i in cc:\n",
        "        u= np.mean(i)\n",
        "    return u\n",
        "\n",
        "def diameter(x):\n",
        "    d=GraphBase.diameter(x,directed=False)\n",
        "    return d\n",
        "\n",
        "def eigenvector(x):\n",
        "    e=np.mean(sorted(GraphBase.eigenvector_centrality(x,directed=False)))\n",
        "    return e\n",
        "\n",
        "def hub_score(x):\n",
        "    h=np.mean(sorted(GraphBase.hub_score(x,weights=None)))\n",
        "    return h\n",
        "\n",
        "#def independence_number(x):\n",
        " #   i=GraphBase.independence_number(x)\n",
        "  #  return i\n",
        "\n",
        "def knn(x):\n",
        "    y= GraphBase.knn(x)\n",
        "    for i in y:\n",
        "        k= np.nanmean(sorted(i))\n",
        "    return k\n",
        "\n",
        "def pagerank(x):\n",
        "    p=np.mean(Graph.pagerank(x, vertices=None, directed=True, damping=0.85))\n",
        "    return p\n",
        "\n",
        "def transitivity(x):\n",
        "    t=GraphBase.transitivity_undirected(x)\n",
        "    return t\n",
        "\n",
        "#def modularity(x):\n",
        " #   m=GraphBase.modularity(x)\n",
        "  #  return m\n",
        "\n",
        "def mean_degree(x):\n",
        "    t= np.mean(GraphBase.degree(x, mode='ALL', loops=True))\n",
        "    return t\n",
        "\n",
        "def second_moment(x):\n",
        "    t=np.var(GraphBase.degree(x, mode='ALL', loops=True))\n",
        "    return t\n",
        "\n",
        "def entropy_degree_sequence(x):\n",
        "    entropia=Shannon_entropy(sorted(GraphBase.degree(x, mode='ALL', loops=True)))\n",
        "    return entropia\n",
        "\n",
        "def Shannon_entropy(distribution):\n",
        "    entropia=stats.entropy(distribution)\n",
        "    return entropia\n",
        "\n",
        "\n",
        "def complexidade(x):\n",
        "   media_grau = np.mean(sorted(GraphBase.degree(x, mode='ALL', loops=True)))\n",
        "   segundo_momento = np.var(sorted((GraphBase.degree(x, mode='ALL', loops=True))))\n",
        "   return (segundo_momento / media_grau)\n",
        "# np.seterr(divide='ignore')\n",
        "\n",
        "def kcore(x):\n",
        "    t=np.mean(Graph.coreness(x,mode='ALL'))\n",
        "    return t\n",
        "\n",
        "def nodal_eff(g):\n",
        "    \"\"\"\n",
        "    This function calculates the nodal efficiency of a weighted graph object.\n",
        "    Created by: Loukas Serafeim (seralouk), Nov 2017\n",
        "\n",
        "    Args:\n",
        "     g: A igraph Graph() object.\n",
        "    Returns:\n",
        "     The nodal efficiency of each node of the graph\n",
        "    \"\"\"\n",
        "\n",
        "    sp = Graph.shortest_paths_dijkstra(g,weights = None)\n",
        "    sp = np.asarray(sp)\n",
        "    with np.errstate(divide='ignore'):\n",
        "        temp = 1.0 / sp\n",
        "    np.fill_diagonal(temp, 0)\n",
        "    N = temp.shape[0]\n",
        "    ne = ( 1.0 / (N - 1)) * np.apply_along_axis(sum, 0, temp)\n",
        "    for i in ne:\n",
        "        t=np.mean(sorted(ne))\n",
        "    return t\n",
        "\n",
        "def diversity(x):\n",
        "    u=GraphBase.diversity(x, weights=None)\n",
        "    return(np.mean(u))\n",
        "\n",
        "def eccentricity(x):\n",
        "    u=GraphBase.eccentricity(x)\n",
        "    return np.mean(u)\n",
        "\n",
        "def edge_conectivity(x):\n",
        "    clusters    = x.clusters()\n",
        "    giant       = clusters.giant() ## using the biggest component as an example, you can use the others here.\n",
        "    #communities = giant.community_spinglass()\n",
        "    t= GraphBase.edge_connectivity(giant)\n",
        "    return t\n",
        "def reciprocity(x):\n",
        "    u= GraphBase.reciprocity(x,ignore_loops=True, mode=\"default\")\n",
        "    return u\n",
        "def average_path_length(x):\n",
        "    apl=GraphBase.average_path_length(x,directed=False, unconn=True)\n",
        "    return apl\n",
        "\n",
        "def tree_spaning(x):\n",
        "    s=Graph.spanning_tree(x)\n",
        "    return s\n",
        "\n",
        "def community_fastgreedy(x):\n",
        "    u= Graph.community_fastgreedy(x, weights=None)\n",
        "    t= VertexDendrogram.as_clustering(u)\n",
        "    return t\n",
        "\n",
        "def community_infomap(x):\n",
        "    u= Graph.community_infomap(x, edge_weights=None)\n",
        "\n",
        "    return u\n",
        "\n",
        "\n",
        "\n",
        "def community_leading_eigenvector(x):\n",
        "    u= Graph.community_leading_eigenvector(x)\n",
        "    return u\n",
        "\n",
        "def community_label_propagation(x):\n",
        "    u=Graph.community_label_propagation(x,weights=None)\n",
        "    return u\n",
        "\n",
        "\n",
        "def community_multilevel(x):\n",
        "    u=Graph.community_multilevel(x, weights=None, return_levels=False)\n",
        "    return u\n",
        "\n",
        "def community_edge_betweenness(x):\n",
        "    clusters    = x.clusters()\n",
        "    giant       = clusters.giant() ## using the biggest component as an example, you can use the others here.\n",
        "    #communities = giant.community_spinglass()\n",
        "    #t= GraphBase.edge_connectivity(giant)\n",
        "    u= Graph.community_edge_betweenness(giant, directed=False, weights=None)\n",
        "    return u\n",
        "\n",
        "def community_spinglass(x):\n",
        "    clusters    = x.clusters()\n",
        "    giant       = clusters.giant() ## using the biggest component as an example, you can use the others here.\n",
        "    communities = giant.community_spinglass()\n",
        "\n",
        "    #u=Graph.community_spinglass(x)\n",
        "    #return u\n",
        "    return communities\n",
        "\n",
        "def community_walktrap(x):\n",
        "    clusters    = x.clusters()\n",
        "    giant       = clusters.giant() ## using the biggest component as an example, you can use the others here.\n",
        "    #communities = giant.community_spinglass()\n",
        "    #t= GraphBase.edge_connectivity(giant)\n",
        "    u= Graph.community_walktrap(giant, weights=None)\n",
        "\n",
        "#### FUNTION for compute all measure\n",
        "def compute_all_features(list_graph):\n",
        "    list_assortativity=[]\n",
        "    list_average_path=[]\n",
        "    list_betweenness=[]\n",
        "    list_closeness=[]\n",
        "    list_diameter=[]\n",
        "    list_eigenvector=[]\n",
        "    list_hub_score=[]\n",
        "    list_knn=[]\n",
        "    list_modularity=[]\n",
        "    list_transitivity=[]\n",
        "    list_pagerank=[]\n",
        "    list_mean_distribution_degree=[]\n",
        "    list_second_moment_degree=[]\n",
        "    list_entropy_degree=[]\n",
        "    list_spaning=[]\n",
        "\n",
        "    list_complexidade=[]\n",
        "    list_kcore=[]\n",
        "    list_effiency=[]\n",
        "    list_spaning1=[]\n",
        "    list_community_fatgreedy=[]\n",
        "    list_community_fatgreedy1=[]\n",
        "    list_community_fatgreedy2=[]\n",
        "    list_community_infomap=[]\n",
        "    list_community_infomap1=[]\n",
        "    list_community_infomap2=[]\n",
        "    list_community_leading_eigenvector=[]\n",
        "    list_community_leading_eigenvector1=[]\n",
        "    list_community_leading_eigenvector2=[]\n",
        "    list_community_label_propagation=[]\n",
        "    list_community_label_propagation1=[]\n",
        "    list_community_label_propagation2=[]\n",
        "    list_community_multilevel=[]\n",
        "    list_community_multilevel1=[]\n",
        "    list_community_multilevel2=[]\n",
        "    list_community_optimal_modularity=[]\n",
        "    list_community_optimal_modularity1=[]\n",
        "    list_community_optimal_modularity2=[]\n",
        "    list_community_edge_betwennes=[]\n",
        "    list_community_edge_betwennes1=[]\n",
        "    list_community_edge_betwennes2=[]\n",
        "    list_community_edge_betwennes3=[]\n",
        "    list_community_spinglass=[]\n",
        "    list_community_spinglass1=[]\n",
        "    list_community_spinglass2=[]\n",
        "    list_community_walktrap=[]\n",
        "    list_community_walktrap1=[]\n",
        "    list_community_walktrap2=[]\n",
        "    list_community_walktrap3=[]\n",
        "    list_density=[]\n",
        "    list_diversity=[]\n",
        "    list_eccentricity=[]\n",
        "    list_edge_connectivity=[]\n",
        "    list_reciprocity=[]\n",
        "    list_modularity=[]\n",
        "    list_label=[]\n",
        "    list_final=[]\n",
        "    for v in list_graph:\n",
        "        list_assortativity.append(assortativity(v))\n",
        "        list_average_path.append(average_path_length(v))\n",
        "        list_betweenness.append(betweenness(v))\n",
        "        list_closeness.append(closeness(v))\n",
        "        list_diameter.append(diameter(v))\n",
        "        list_eigenvector.append(eigenvector(v))\n",
        "        list_hub_score.append(hub_score(v))\n",
        "\n",
        "        list_knn.append(knn(v))\n",
        "\n",
        "        list_transitivity.append(transitivity(v))\n",
        "        list_pagerank.append(pagerank(v))\n",
        "        list_spaning.append(tree_spaning(v))\n",
        "        list_community_fatgreedy.append(community_fastgreedy(v))\n",
        "        list_community_infomap.append(community_infomap(v))\n",
        "        list_community_leading_eigenvector.append(community_leading_eigenvector(v))\n",
        "        list_mean_distribution_degree.append(mean_degree(v))\n",
        "        list_second_moment_degree.append(second_moment(v))\n",
        "        list_entropy_degree.append(entropy_degree_sequence(v))\n",
        "        list_complexidade.append(complexidade(v))\n",
        "        list_kcore.append(kcore(v))\n",
        "        list_effiency.append(nodal_eff(v))\n",
        "        list_community_label_propagation.append(community_label_propagation(v))\n",
        "        list_community_multilevel.append(community_multilevel(v))\n",
        "        list_community_edge_betwennes.append(community_edge_betweenness(v))\n",
        "        list_community_spinglass.append(community_spinglass(v))\n",
        "\n",
        "        list_diversity.append(diversity(v))\n",
        "        list_eccentricity.append(eccentricity(v))\n",
        "        list_density.append(GraphBase.density(v, loops=False))\n",
        "        list_edge_connectivity.append(edge_conectivity(v))\n",
        "        list_reciprocity.append(reciprocity(v))\n",
        "\n",
        "    for i in list_spaning:\n",
        "        list_spaning1.append(average_path_length(i))\n",
        "\n",
        "    for i in list_community_fatgreedy:\n",
        "        list_community_fatgreedy1.append(VertexClustering.giant(i))\n",
        "    for i in list_community_fatgreedy1:\n",
        "        list_community_fatgreedy2.append(average_path_length(i))\n",
        "\n",
        "    for i in list_community_infomap:\n",
        "        list_community_infomap1.append(VertexClustering.giant(i))\n",
        "    for i in list_community_infomap1:\n",
        "        list_community_infomap2.append(average_path_length(i))\n",
        "\n",
        "    for i in list_community_leading_eigenvector:\n",
        "        list_community_leading_eigenvector1.append(VertexClustering.giant(i))\n",
        "    for i in list_community_leading_eigenvector1:\n",
        "        list_community_leading_eigenvector2.append(average_path_length(i))\n",
        "\n",
        "    for i in list_community_multilevel:\n",
        "        list_community_multilevel1.append(VertexClustering.giant(i))\n",
        "    for i in list_community_multilevel1:\n",
        "        list_community_multilevel2.append(average_path_length(i))\n",
        "\n",
        "    for i in list_community_edge_betwennes:\n",
        "        list_community_edge_betwennes1.append(VertexDendrogram.as_clustering(i))\n",
        "    for i in list_community_edge_betwennes1:\n",
        "        list_community_edge_betwennes2.append(VertexClustering.giant(i))\n",
        "    for i in list_community_edge_betwennes2:\n",
        "        list_community_edge_betwennes3.append(average_path_length(i))\n",
        "\n",
        "    for i in list_community_spinglass:\n",
        "        list_community_spinglass1.append(VertexClustering.giant(i))\n",
        "    for i in list_community_spinglass1:\n",
        "        list_community_spinglass2.append(average_path_length(i))\n",
        "\n",
        "\n",
        "\n",
        "    for i in list_community_label_propagation:\n",
        "        list_community_label_propagation1.append(VertexClustering.giant(i))\n",
        "    for i in list_community_label_propagation1:\n",
        "        list_community_label_propagation2.append(average_path_length(i))\n",
        "\n",
        "    list_final = [list_assortativity, list_average_path, list_betweenness, list_closeness, list_diameter,list_eigenvector, list_hub_score, list_knn, list_transitivity, list_pagerank, list_spaning1,list_community_fatgreedy2, list_community_infomap2, list_community_leading_eigenvector2,list_mean_distribution_degree, list_second_moment_degree, list_entropy_degree, list_complexidade,list_kcore, list_effiency, list_community_multilevel2, list_community_label_propagation2,list_community_edge_betwennes3, list_community_spinglass2, list_diversity,list_eccentricity, list_density, list_reciprocity]# print list_spaning1\n",
        "   # df = DataFrame(list_final)\n",
        "    return list_final\n"
      ]
    }
  ]
}